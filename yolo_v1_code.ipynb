{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "extreme-contact",
   "metadata": {},
   "source": [
    "# yolo-v1 code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "general-helping",
   "metadata": {},
   "source": [
    "## yolo-v1 网络结构\n",
    "输入：Batch x C x H x W  \n",
    "输出：Batch x GridCell x GridCell x (xywh-c-cls x BBox)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "respected-juvenile",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T06:52:50.170545Z",
     "start_time": "2021-04-20T06:52:47.360333Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds: torch.Size([3, 13, 13, 30])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/intellif/anaconda3/envs/object_tracking/lib/python3.7/site-packages/torch/nn/functional.py:1639: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import math\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "__all__ = ['ResNet', 'resnet18', 'resnet34', 'resnet50', 'resnet101',\n",
    "           'resnet152']\n",
    "\n",
    "\n",
    "model_urls = {\n",
    "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
    "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
    "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
    "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
    "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
    "}\n",
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"3x3 convolution with padding\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class detnet_bottleneck(nn.Module):\n",
    "    # no expansion\n",
    "    # dilation = 2\n",
    "    # type B use 1x1 conv\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1, block_type='A'):\n",
    "        super(detnet_bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=2, bias=False,dilation=2)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
    "\n",
    "        self.downsample = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes or block_type=='B':\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.downsample(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=1470):\n",
    "        self.inplanes = 64\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        # self.layer5 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.layer5 = self._make_detnet_layer(in_channels=2048)\n",
    "        # self.avgpool = nn.AvgPool2d(14) #fit 448 input size\n",
    "        # self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "        self.conv_end = nn.Conv2d(256, 30, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn_end = nn.BatchNorm2d(30)\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def _make_detnet_layer(self,in_channels):\n",
    "        layers = []\n",
    "        layers.append(detnet_bottleneck(in_planes=in_channels, planes=256, block_type='B'))\n",
    "        layers.append(detnet_bottleneck(in_planes=256, planes=256, block_type='A'))\n",
    "        layers.append(detnet_bottleneck(in_planes=256, planes=256, block_type='A'))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.layer5(x)\n",
    "        # x = self.avgpool(x)\n",
    "        # x = x.view(x.size(0), -1)\n",
    "        # x = self.fc(x)\n",
    "        x = self.conv_end(x)\n",
    "        x = self.bn_end(x)\n",
    "        x = F.sigmoid(x) #归一化到0-1\n",
    "        # x = x.view(-1,7,7,30)\n",
    "        x = x.permute(0,2,3,1) #(-1,7,7,30)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "def resnet18(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-18 model.\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet18']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet34(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-34 model.\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet34']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet50(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-50 model.\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet50']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet101(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-101 model.\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 4, 23, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet101']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet152(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-152 model.\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 8, 36, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet152']))\n",
    "    return model\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    import torch\n",
    "    import torchvision\n",
    "    \n",
    "    def copy_params(model1, model2, restrict=False):\n",
    "        '''\n",
    "        model1: dst model\n",
    "        model2: src model\n",
    "        restrict: \n",
    "        '''\n",
    "        model1_state_dict = model1.state_dict()\n",
    "        model2_state_dict = model2.state_dict()\n",
    "        if restrict:\n",
    "            pass\n",
    "        else:\n",
    "            collected_dict = {k: v for k, v in model2_state_dict.items() if k in model1_state_dict}\n",
    "        \n",
    "            model1_state_dict.update(collected_dict)\n",
    "        \n",
    "        model1.load_state_dict(model1_state_dict)\n",
    "        \n",
    "        return model1\n",
    "\n",
    "    model = resnet50()\n",
    "    pre_model = torchvision.models.resnet50(pretrained=True)\n",
    "    \n",
    "    model = copy_params(model, pre_model, restrict=False)\n",
    "    \n",
    "    H, W = 416, 416\n",
    "    # H, W = 128, 128\n",
    "    # H, W = 208, 208\n",
    "    B = 3\n",
    "    # data = torch.rand(B, 2, 3, W, H)\n",
    "    data = torch.rand(B, 3, W, H)\n",
    "\n",
    "    preds = model(data)\n",
    "    \n",
    "    print(f'preds: {preds.shape}')\n",
    "    # print(f'bbox: {preds[0].shape}')\n",
    "    # print(f'hm: {preds[1].shape}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hungry-organization",
   "metadata": {},
   "source": [
    "## yolo-v1 损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adequate-niagara",
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoding:utf-8\n",
    "#\n",
    "#created by xiongzihua 2017.12.26\n",
    "#\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class yoloLoss(nn.Module):\n",
    "    def __init__(self,S,B,l_coord,l_noobj):\n",
    "        super(yoloLoss,self).__init__()\n",
    "        '''\n",
    "        S: 表示gridcell大小，总共SxS个gridcell。\n",
    "        B: 表示每个gridcell包含B个BBox。\n",
    "        l_noobj: 表示不包含目标\n",
    "        '''\n",
    "        self.S = S\n",
    "        self.B = B\n",
    "        self.l_coord = l_coord\n",
    "        self.l_noobj = l_noobj\n",
    "\n",
    "    def compute_iou(self, box1, box2):\n",
    "        '''Compute the intersection over union of two set of boxes, each box is [x1,y1,x2,y2].\n",
    "        Args:\n",
    "          box1: (tensor) bounding boxes, sized [N,4].\n",
    "          box2: (tensor) bounding boxes, sized [M,4].\n",
    "        Return:\n",
    "          (tensor) iou, sized [N,M].\n",
    "        \n",
    "        ## IOU在计算过程中，对矩形框进行了扩展，这点用到了矩阵思维。\n",
    "        ## 通常情况下，两个for循环，搞定。但是如何用矩阵思维解决问题，速度更快呢？\n",
    "        ## 首先： 考虑这是一个两级遍历，即box1中每个框要遍历box2中每个框。\n",
    "        ## 其次： 用矩阵思维考虑，先求出交集lt，和abs交集rb。\n",
    "        ## 再次： 计算交集面积。\n",
    "        ## 再次： 并集面积为两个框面积之和减去交集面积。\n",
    "        ## 最后： 进行交并比。\n",
    "        ## 计算过程：\n",
    "        ## 1. 首先对box1进行维度扩展，box1 shape为(N, 4)，选取x1，y1坐标，为box2增加一个维度，即从(N,2)-->(N,1,2)，再对新增维度进行扩展到box2对应尺寸中M的维度。\n",
    "        ## 2. 其次对box2进行维度扩展，box2 shape为(M, 4)，选取x1，y1坐标，为box1增加一个维度，即从(M,2)-->(1,M,2)，再对新增维度进行扩展到box1对应尺寸中N的维度。\n",
    "        ## 3. 进行左上角最大值选取。\n",
    "        ##   注：\n",
    "        ##      1. 为什么要维度扩展呢？\n",
    "        ##      为了做矩阵元素比较，并且要保证两级循环。\n",
    "        ## 4. 进行右下角最小值选取。\n",
    "        ## 5. 计算wh。\n",
    "        ## 6. 计算交集面积。\n",
    "        ## 7. 计算并集面积。\n",
    "        ## 8. 计算IOU。\n",
    "        ## ------------------------------------------------\n",
    "        ## 这里需要补充一下python关于扩展维度的知识点：\n",
    "        ## 这里只做扩展维度的部分，不做congtinguous,view,pemute等的介绍。\n",
    "        ## 特性：扩展维度，就是重复该维度之后的所有维度。\n",
    "        ##    理解:\n",
    "        ##    .> 矩阵维度扩展的本质就是对该扩展的维度之后的维度的重复。\n",
    "        ##    首先：理解扩展的维度，如对矩阵(N,S,S)扩展最后一维，那么该矩阵可以理解为立体矩阵(1,N,1,S,1,S,1)，\n",
    "        ##       其有效维度是第1维，有效长度为长度为N，第3维，有效长度为S，第5维，有效长度为S，其它维度上\n",
    "        ##       有效长度为1，是作为辅助的维度(维度的有效长度为1，实际表示就是标量scalar的维度，就像一维向量一样)。\n",
    "        ##    其次：从维度上讲，扩展矩阵第i个维度，就是扩展立体矩阵第i个维度。\n",
    "        ##    再次：从内容上讲，扩展矩阵第i个维度，就是重复第i维以后的维度，因此可以将第i维以后的\n",
    "        ##       所有维度和所有维度的内容看做一个整体，进行重复。\n",
    "        ##    1> 矩阵(N,S,S)，扩展最后一维，可以理解矩阵为N个(S,S)的二维矩阵，\n",
    "        ##       在(S,S)中每个<i,j>位置都是一个值，此时要对这个值进行扩展，相当\n",
    "        ##       于重复这个值。那么(S,S)的矩阵就成了三维矩阵(S,S,M)，此时看原来\n",
    "        ##       的矩阵，就相当于N个(S,S,M)的三维矩阵。那么扩展后的矩阵就是(N,S,S,M)。\n",
    "        ##       ———————— 根据.>中的理解：\n",
    "        ##       矩阵(N,S,S)的立体矩阵(1,N,1,S,1,S,1)，扩展最后一维，就是重复最后一维，\n",
    "        ##       最后一维是一个scalar，即(1,1)，那么扩展最后一维，就是讲1x1重复M次，\n",
    "        ##       就变成了(1,M)。还原到立体矩阵:\n",
    "        ##       (1,N,1,S,1,S,1)==>(1,N,1,S,1,S,1,M)==>(1,N,1,S,1,S,1,M,1)\n",
    "        ##       简化立体矩阵：(1,N,1,S,1,S,1,M,1)==>(N,S,S,M)\n",
    "        ##    2> 矩阵(N,S,S)，要重复第1维，就是重复(S,S)这个矩阵，即重复第一维以后的维度。\n",
    "        ##       ———————— 根据.>中的理解：\n",
    "        ##       矩阵(N,S,S)的立体矩阵(1,N,1,S,1,S,1)，扩展第i维，就是重复第i为之后的所有维度的内容。\n",
    "        ##       如扩展第1维，就是重复(S,S)的内容。首先增加第1维度，矩阵维度变成(N,1,S,S)，即显示化第1个维度。\n",
    "        ##       其次对第1维度进行expand，即重复显示化维度后的第1维之后的内容。\n",
    "        ## 目标：扩展某个维度，从(d1,d2,d3)扩展到(d1,d2,d3,d4)\n",
    "        ## 步骤：\n",
    "        ## 1> 显示化隐藏的立体矩阵中对应的维度。即在需要扩展的维度的位置，增加一个维度；\n",
    "        ## 2> 对该增加维度进行expand\n",
    "        ## ------------------------------------------------\n",
    "        ## ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "        '''\n",
    "        ## IOU矩阵尺寸(N, M) = (N, 4) x (4, M)\n",
    "        N = box1.size(0)\n",
    "        M = box2.size(0)\n",
    "\n",
    "        ## left-top即左上角点\n",
    "        ## 选取左上角点x的最大值和y的最大值，即交集部分的left-top。\n",
    "        lt = torch.max(\n",
    "            box1[:,:2].unsqueeze(1).expand(N,M,2),  # [N,2] -> [N,1,2] -> [N,M,2]\n",
    "            box2[:,:2].unsqueeze(0).expand(N,M,2),  # [M,2] -> [1,M,2] -> [N,M,2]\n",
    "        )\n",
    "\n",
    "        ## right-bottom即右下角点\n",
    "        ## 选取右下角点x的最小值和y的最小值，即交际部分的right-bottom。\n",
    "        rb = torch.min(\n",
    "            box1[:,2:].unsqueeze(1).expand(N,M,2),  # [N,2] -> [N,1,2] -> [N,M,2]\n",
    "            box2[:,2:].unsqueeze(0).expand(N,M,2),  # [M,2] -> [1,M,2] -> [N,M,2]\n",
    "        )\n",
    "\n",
    "        wh = rb - lt  # [N,M,2]\n",
    "        wh[wh<0] = 0  # clip at 0\n",
    "        inter = wh[:,:,0] * wh[:,:,1]  # [N,M]\n",
    "\n",
    "        area1 = (box1[:,2]-box1[:,0]) * (box1[:,3]-box1[:,1])  # [N,]\n",
    "        area2 = (box2[:,2]-box2[:,0]) * (box2[:,3]-box2[:,1])  # [M,]\n",
    "        area1 = area1.unsqueeze(1).expand_as(inter)  # [N,] -> [N,1] -> [N,M]\n",
    "        area2 = area2.unsqueeze(0).expand_as(inter)  # [M,] -> [1,M] -> [N,M]\n",
    "\n",
    "        iou = inter / (area1 + area2 - inter)\n",
    "        return iou\n",
    "    def forward(self,pred_tensor,target_tensor):\n",
    "        '''\n",
    "        pred_tensor: (tensor) size(batchsize,S,S,Bx5+20=30) [x,y,w,h,c]\n",
    "        target_tensor: (tensor) size(batchsize,S,S,30)\n",
    "        '''\n",
    "        ## 获取BatchSize\n",
    "        N = pred_tensor.size()[0]\n",
    "        ## 包含目标的mask为c>0\n",
    "        coo_mask = target_tensor[:,:,:,4] > 0  # (B, S, S)\n",
    "        ## 不包含目标的mask为c=0\n",
    "        noo_mask = target_tensor[:,:,:,4] == 0  # (B, S, S)\n",
    "        ## 将mask进行扩展，扩展到最后一维的尺寸。\n",
    "        ## 一定要先添加最后一个维度，在进行最后新添加的这个维度的扩展。\n",
    "        ##     可以想想一下B个SxS这样二维矩阵，添加最后一个维度后，\n",
    "        ##     即SxS中每个元素都是1x1的，进行扩展，就是1xE，再放\n",
    "        ##     到SxS矩阵中，就形成立方体，二维矩阵。\n",
    "        coo_mask = coo_mask.unsqueeze(-1).expand_as(target_tensor)  # (B, S, S, 30)\n",
    "        noo_mask = noo_mask.unsqueeze(-1).expand_as(target_tensor)  # (B, S, S, 30)\n",
    "\n",
    "        ## python中[]的用法：\n",
    "        ## pred_tensor[coo_mask]表示取出coo_mask中不为0的元素。\n",
    "        ##    1. 这些取出来的元素构成一维，即这种形式取出来的元素并不关心原来矩阵中的维度。\n",
    "        ##    2. 这些不为0的元素有个特点，就是整行整行取出，为什么呢？因为coo_mask进行了expand_as(...)。\n",
    "        ## 所以pred_tensor[coo_mask]的结果才能够执行view(-1, 30）。\n",
    "        ## 注：这种操作实际上可以用select(...)获取。\n",
    "        coo_pred = pred_tensor[coo_mask].view(-1,30)\n",
    "        ## 取出x11y11x12y12c11x21y21x22y22c21这10个元素。\n",
    "        ## 注意查看contiguous(...)和view(...)两个方法的使用。\n",
    "        box_pred = coo_pred[:,:10].contiguous().view(-1,5) #box[x1,y1,w1,h1,c1]\n",
    "        class_pred = coo_pred[:,10:]                       #[x2,y2,w2,h2,c2]\n",
    "        \n",
    "        coo_target = target_tensor[coo_mask].view(-1,30)\n",
    "        box_target = coo_target[:,:10].contiguous().view(-1,5)  # (N, 5)\n",
    "        class_target = coo_target[:,10:]\n",
    "\n",
    "        # compute not contain obj loss\n",
    "        noo_pred = pred_tensor[noo_mask].view(-1,30)\n",
    "        noo_target = target_tensor[noo_mask].view(-1,30)\n",
    "        noo_pred_mask = torch.cuda.ByteTensor(noo_pred.size())\n",
    "        noo_pred_mask.zero_()\n",
    "        ## 表示gridcell中是否包含对象，此时对应B个BBox，即计算所有B个BBox的信息，对应nooobj_loss计算了B个BBox的C。\n",
    "        noo_pred_mask[:,4]=1;noo_pred_mask[:,9]=1\n",
    "        noo_pred_c = noo_pred[noo_pred_mask] #noo pred只需要计算 c 的损失 size[-1,2]\n",
    "        noo_target_c = noo_target[noo_pred_mask]\n",
    "        ## 计算confidence不包含目标的loss\n",
    "        nooobj_loss = F.mse_loss(noo_pred_c,noo_target_c,size_average=False)\n",
    "\n",
    "        #compute contain obj loss\n",
    "        coo_response_mask = torch.cuda.ByteTensor(box_target.size())  # (N, 5)\n",
    "        coo_response_mask.zero_()\n",
    "        coo_not_response_mask = torch.cuda.ByteTensor(box_target.size())  # (N, 5)\n",
    "        coo_not_response_mask.zero_()\n",
    "        box_target_iou = torch.zeros(box_target.size()).cuda()  # (N, 5)\n",
    "        ## for循环表示取SxS个gridcell中，每个gridcell包含B个BBox，求每个gridcell中B个BBox与对应位置的gridcell的IOU最大值。\n",
    "        ## 比如：第(i,j)位置的gridcell，包含B个BBox，此时对比pred和target中该位置的B个BBox，获取该gridcell中最大IOU的那个BBox。\n",
    "        for i in range(0,box_target.size()[0],2): #choose the best iou box\n",
    "            ## 计算pred的左上角点和右下角点。\n",
    "            box1 = box_pred[i:i+2]  # box_pred==>(N, 5)(xywhc)  box1==>(2, 5)(xywhc)\n",
    "            box1_xyxy = Variable(torch.FloatTensor(box1.size()))\n",
    "            box1_xyxy[:,:2] = box1[:,:2]/14. -0.5*box1[:,2:4]  # 中心点减去一半的wh，即左上角点。\n",
    "            box1_xyxy[:,2:4] = box1[:,:2]/14. +0.5*box1[:,2:4]  # 中心点加上一半的wh，即右下角点。\n",
    "            ## 计算target的左上角点和右下角点。\n",
    "            box2 = box_target[i].view(-1,5)\n",
    "            box2_xyxy = Variable(torch.FloatTensor(box2.size()))\n",
    "            box2_xyxy[:,:2] = box2[:,:2]/14. -0.5*box2[:,2:4]\n",
    "            box2_xyxy[:,2:4] = box2[:,:2]/14. +0.5*box2[:,2:4]\n",
    "            ## 计算IOU。\n",
    "            iou = self.compute_iou(box1_xyxy[:,:4],box2_xyxy[:,:4]) #[2,1]\n",
    "            max_iou,max_index = iou.max(0)\n",
    "            max_index = max_index.data.cuda()  # 这里的max_index表示B个BBox的最大IOU的位置。当B=2，表示2组<(pred-0, target-0), (pred-1, target-1)>中最大IOU的那个index。\n",
    "            \n",
    "            ## 这里实际上就是一个互斥逻辑的判断。\n",
    "            ## 注：此时的B只能等于2，大于2，此处逻辑就不能满足。\n",
    "            ## 如果max_index=0，则i+max_index=i,i+1-max_index=i+1；\n",
    "            ## 如果max_index=1，则i+max_index=i+1,i+1-max_index=i；\n",
    "            coo_response_mask[i+max_index]=1\n",
    "            coo_not_response_mask[i+1-max_index]=1\n",
    "\n",
    "            #####\n",
    "            # we want the confidence score to equal the\n",
    "            # intersection over union (IOU) between the predicted box\n",
    "            # and the ground truth\n",
    "            #####\n",
    "            box_target_iou[i+max_index,torch.LongTensor([4]).cuda()] = (max_iou).data.cuda()\n",
    "        box_target_iou = Variable(box_target_iou).cuda()\n",
    "        #1.response loss\n",
    "        box_pred_response = box_pred[coo_response_mask].view(-1,5)\n",
    "        box_target_response_iou = box_target_iou[coo_response_mask].view(-1,5)\n",
    "        box_target_response = box_target[coo_response_mask].view(-1,5)\n",
    "        ## contain obj confidence loss\n",
    "        contain_loss = F.mse_loss(box_pred_response[:,4],box_target_response_iou[:,4],size_average=False)\n",
    "        ## xy和wh loss\n",
    "        loc_loss = F.mse_loss(box_pred_response[:,:2],box_target_response[:,:2],size_average=False) + F.mse_loss(torch.sqrt(box_pred_response[:,2:4]),torch.sqrt(box_target_response[:,2:4]),size_average=False)\n",
    "        #2.not response loss\n",
    "        box_pred_not_response = box_pred[coo_not_response_mask].view(-1,5)\n",
    "        box_target_not_response = box_target[coo_not_response_mask].view(-1,5)\n",
    "        box_target_not_response[:,4]= 0\n",
    "        #not_contain_loss = F.mse_loss(box_pred_response[:,4],box_target_response[:,4],size_average=False)\n",
    "        \n",
    "        #I believe this bug is simply a typo\n",
    "        not_contain_loss = F.mse_loss(box_pred_not_response[:,4], box_target_not_response[:,4],size_average=False)\n",
    "\n",
    "        #3.class loss\n",
    "        class_loss = F.mse_loss(class_pred,class_target,size_average=False)\n",
    "        \n",
    "        ## loc_loss: xy and wh\n",
    "        ## contain_loss: 包含目标，且与目标IOU最大的那个gridcell的某个BBox\n",
    "        ## not_contain_loss: 包含目标，且不是与目标IOU最大的那些(此处应该是那个，因为B=2)BBox\n",
    "        ## nooobj_loss: 不包含目标的gridcell的confidence\n",
    "        ## class_loss: 类别loss\n",
    "        return (self.l_coord*loc_loss + 2*contain_loss + not_contain_loss + self.l_noobj*nooobj_loss + class_loss)/N\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('object_tracking': conda)",
   "language": "python",
   "name": "python371064bitobjecttrackingconda66c6f2efc4d740808a4620e21504b8f3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "258.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
