{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "champion-wellington",
   "metadata": {},
   "source": [
    "## yolo-v1 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olive-apparel",
   "metadata": {
    "code_folding": [
     127,
     129,
     131,
     134,
     145,
     156,
     167,
     172,
     206,
     217,
     248,
     253,
     264
    ]
   },
   "outputs": [],
   "source": [
    "#encoding:utf-8\n",
    "#\n",
    "#created by xiongzihua\n",
    "#\n",
    "'''\n",
    "txt描述文件 image_name.jpg x y w h c x y w h c 这样就是说一张图片中有两个目标\n",
    "'''\n",
    "import os\n",
    "import sys\n",
    "import os.path\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class yoloDataset(data.Dataset):\n",
    "    image_size = 448\n",
    "    def __init__(self,root,list_file,train,transform):\n",
    "        print('data init')\n",
    "        self.root=root\n",
    "        self.train = train\n",
    "        self.transform=transform\n",
    "        self.fnames = []\n",
    "        self.boxes = []\n",
    "        self.labels = []\n",
    "        self.mean = (123,117,104)#RGB\n",
    "\n",
    "        if isinstance(list_file, list):\n",
    "            # Cat multiple list files together.\n",
    "            # This is especially useful for voc07/voc12 combination.\n",
    "            tmp_file = '/tmp/listfile.txt'\n",
    "            os.system('cat %s > %s' % (' '.join(list_file), tmp_file))\n",
    "            list_file = tmp_file\n",
    "\n",
    "        with open(list_file) as f:\n",
    "            lines  = f.readlines()\n",
    "\n",
    "        for line in lines:\n",
    "            splited = line.strip().split()\n",
    "            self.fnames.append(splited[0])\n",
    "            num_boxes = (len(splited) - 1) // 5\n",
    "            box=[]\n",
    "            label=[]\n",
    "            for i in range(num_boxes):\n",
    "                x = float(splited[1+5*i])\n",
    "                y = float(splited[2+5*i])\n",
    "                x2 = float(splited[3+5*i])\n",
    "                y2 = float(splited[4+5*i])\n",
    "                c = splited[5+5*i]\n",
    "                box.append([x,y,x2,y2])\n",
    "                label.append(int(c)+1)\n",
    "            self.boxes.append(torch.Tensor(box))\n",
    "            self.labels.append(torch.LongTensor(label))\n",
    "        self.num_samples = len(self.boxes)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        ## 读取图片\n",
    "        fname = self.fnames[idx]\n",
    "        img = cv2.imread(os.path.join(self.root+fname))\n",
    "        print(f'[===]  img: {img.shape}')\n",
    "        ## 获取boxes信息\n",
    "        boxes = self.boxes[idx].clone()\n",
    "        labels = self.labels[idx].clone()\n",
    "\n",
    "        ## 如果训练，进行各种数据增强。\n",
    "        if self.train:\n",
    "            img = self.random_bright(img)\n",
    "            img, boxes = self.random_flip(img, boxes)\n",
    "            img,boxes = self.randomScale(img,boxes)\n",
    "            img = self.randomBlur(img)\n",
    "            img = self.RandomBrightness(img)\n",
    "            img = self.RandomHue(img)\n",
    "            img = self.RandomSaturation(img)\n",
    "            img,boxes,labels = self.randomShift(img,boxes,labels)\n",
    "            img,boxes,labels = self.randomCrop(img,boxes,labels)\n",
    "        # #debug\n",
    "        # box_show = boxes.numpy().reshape(-1)\n",
    "        # print(box_show)\n",
    "        # img_show = self.BGR2RGB(img)\n",
    "        # pt1=(int(box_show[0]),int(box_show[1])); pt2=(int(box_show[2]),int(box_show[3]))\n",
    "        # cv2.rectangle(img_show,pt1=pt1,pt2=pt2,color=(0,255,0),thickness=1)\n",
    "        # plt.figure()\n",
    "        \n",
    "        # # cv2.rectangle(img,pt1=(10,10),pt2=(100,100),color=(0,255,0),thickness=1)\n",
    "        # plt.imshow(img_show)\n",
    "        # plt.show()\n",
    "        # #debug\n",
    "        ## 获取图像尺寸\n",
    "        h,w,_ = img.shape\n",
    "        ## boxes([xyxy]/[xywh])进行压缩到[0,1]之间。\n",
    "        ## 这里依然用到矩阵元素相除操作，即需要进行同维度矩阵构建。\n",
    "        boxes /= torch.Tensor([w,h,w,h]).expand_as(boxes)\n",
    "        img = self.BGR2RGB(img) #because pytorch pretrained model use RGB\n",
    "        img = self.subMean(img,self.mean) #减去均值\n",
    "        img = cv2.resize(img,(self.image_size,self.image_size))\n",
    "        target = self.encoder(boxes,labels)# 7x7x30\n",
    "        for t in self.transform:\n",
    "            img = t(img)\n",
    "\n",
    "        return img,target\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def encoder(self,boxes,labels):\n",
    "        '''\n",
    "        boxes (tensor) [[x1,y1,x2,y2],[]]  # 此时boxes已经归一化到了[0,1]的gridcell上。\n",
    "        labels (tensor) [...]\n",
    "        return 7x7x30\n",
    "        '''\n",
    "        grid_num = 14\n",
    "        target = torch.zeros((grid_num,grid_num,30))\n",
    "        ## cell_size:表示一个gridcell在[0,1]之间表示的长度。如grid_num=7，此时每个gridcell的size为1/7。\n",
    "        cell_size = 1./grid_num\n",
    "        wh = boxes[:,2:]-boxes[:,:2]\n",
    "        ## cxcy(N,2)\n",
    "        cxcy = (boxes[:,2:]+boxes[:,:2])/2\n",
    "        for i in range(cxcy.size()[0]):\n",
    "            cxcy_sample = cxcy[i]\n",
    "            ## 获取gridcell的坐标。\n",
    "            ij = (cxcy_sample/cell_size).ceil()-1 #\n",
    "            ## 将target对应gridcell位置上的confidence置1。\n",
    "            target[int(ij[1]),int(ij[0]),4] = 1\n",
    "            target[int(ij[1]),int(ij[0]),9] = 1\n",
    "            target[int(ij[1]),int(ij[0]),int(labels[i])+9] = 1\n",
    "            ## 左上角点的坐标\n",
    "            xy = ij*cell_size #匹配到的网格的左上角相对坐标\n",
    "            ## delta_xy表示的是中心点距离中心点所在的gridcell的左上角点的距离，并归一化的gridcell的尺寸内。\n",
    "            delta_xy = (cxcy_sample -xy)/cell_size\n",
    "            ## wh是相对整张图片的值\n",
    "            target[int(ij[1]),int(ij[0]),2:4] = wh[i]\n",
    "            ## delta_xy是相对中心点所在的gridcell的值。\n",
    "            target[int(ij[1]),int(ij[0]),:2] = delta_xy\n",
    "            ## wh是相对整张图片的值\n",
    "            target[int(ij[1]),int(ij[0]),7:9] = wh[i]\n",
    "            ## delta_xy是相对中心点所在的gridcell的值。\n",
    "            target[int(ij[1]),int(ij[0]),5:7] = delta_xy\n",
    "        return target\n",
    "    def BGR2RGB(self,img):\n",
    "        return cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    def BGR2HSV(self,img):\n",
    "        return cv2.cvtColor(img,cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    def HSV2BGR(self,img):\n",
    "        return cv2.cvtColor(img,cv2.COLOR_HSV2BGR)\n",
    "    \n",
    "    def RandomBrightness(self,bgr):\n",
    "        if random.random() < 0.5:\n",
    "            hsv = self.BGR2HSV(bgr)\n",
    "            h,s,v = cv2.split(hsv)\n",
    "            adjust = random.choice([0.5,1.5])\n",
    "            v = v*adjust\n",
    "            v = np.clip(v, 0, 255).astype(hsv.dtype)\n",
    "            hsv = cv2.merge((h,s,v))\n",
    "            bgr = self.HSV2BGR(hsv)\n",
    "        return bgr\n",
    "\n",
    "    def RandomSaturation(self,bgr):\n",
    "        if random.random() < 0.5:\n",
    "            hsv = self.BGR2HSV(bgr)\n",
    "            h,s,v = cv2.split(hsv)\n",
    "            adjust = random.choice([0.5,1.5])\n",
    "            s = s*adjust\n",
    "            s = np.clip(s, 0, 255).astype(hsv.dtype)\n",
    "            hsv = cv2.merge((h,s,v))\n",
    "            bgr = self.HSV2BGR(hsv)\n",
    "        return bgr\n",
    "\n",
    "    def RandomHue(self,bgr):\n",
    "        if random.random() < 0.5:\n",
    "            hsv = self.BGR2HSV(bgr)\n",
    "            h,s,v = cv2.split(hsv)\n",
    "            adjust = random.choice([0.5,1.5])\n",
    "            h = h*adjust\n",
    "            h = np.clip(h, 0, 255).astype(hsv.dtype)\n",
    "            hsv = cv2.merge((h,s,v))\n",
    "            bgr = self.HSV2BGR(hsv)\n",
    "        return bgr\n",
    "\n",
    "    def randomBlur(self,bgr):\n",
    "        if random.random()<0.5:\n",
    "            bgr = cv2.blur(bgr,(5,5))\n",
    "        return bgr\n",
    "\n",
    "    def randomShift(self,bgr,boxes,labels):\n",
    "        #平移变换\n",
    "        center = (boxes[:,2:]+boxes[:,:2])/2\n",
    "        if random.random() <0.5:\n",
    "            height,width,c = bgr.shape\n",
    "            after_shfit_image = np.zeros((height,width,c),dtype=bgr.dtype)\n",
    "            after_shfit_image[:,:,:] = (104,117,123) #bgr\n",
    "            shift_x = random.uniform(-width*0.2,width*0.2)\n",
    "            shift_y = random.uniform(-height*0.2,height*0.2)\n",
    "            #print(bgr.shape,shift_x,shift_y)\n",
    "            #原图像的平移\n",
    "            if shift_x>=0 and shift_y>=0:\n",
    "                after_shfit_image[int(shift_y):,int(shift_x):,:] = bgr[:height-int(shift_y),:width-int(shift_x),:]\n",
    "            elif shift_x>=0 and shift_y<0:\n",
    "                after_shfit_image[:height+int(shift_y),int(shift_x):,:] = bgr[-int(shift_y):,:width-int(shift_x),:]\n",
    "            elif shift_x <0 and shift_y >=0:\n",
    "                after_shfit_image[int(shift_y):,:width+int(shift_x),:] = bgr[:height-int(shift_y),-int(shift_x):,:]\n",
    "            elif shift_x<0 and shift_y<0:\n",
    "                after_shfit_image[:height+int(shift_y),:width+int(shift_x),:] = bgr[-int(shift_y):,-int(shift_x):,:]\n",
    "\n",
    "            shift_xy = torch.FloatTensor([[int(shift_x),int(shift_y)]]).expand_as(center)\n",
    "            center = center + shift_xy\n",
    "            mask1 = (center[:,0] >0) & (center[:,0] < width)\n",
    "            mask2 = (center[:,1] >0) & (center[:,1] < height)\n",
    "            mask = (mask1 & mask2).view(-1,1)\n",
    "            boxes_in = boxes[mask.expand_as(boxes)].view(-1,4)\n",
    "            if len(boxes_in) == 0:\n",
    "                return bgr,boxes,labels\n",
    "            box_shift = torch.FloatTensor([[int(shift_x),int(shift_y),int(shift_x),int(shift_y)]]).expand_as(boxes_in)\n",
    "            boxes_in = boxes_in+box_shift\n",
    "            labels_in = labels[mask.view(-1)]\n",
    "            return after_shfit_image,boxes_in,labels_in\n",
    "        return bgr,boxes,labels\n",
    "\n",
    "    def randomScale(self,bgr,boxes):\n",
    "        #固定住高度，以0.8-1.2伸缩宽度，做图像形变\n",
    "        if random.random() < 0.5:\n",
    "            scale = random.uniform(0.8,1.2)\n",
    "            height,width,c = bgr.shape\n",
    "            bgr = cv2.resize(bgr,(int(width*scale),height))\n",
    "            scale_tensor = torch.FloatTensor([[scale,1,scale,1]]).expand_as(boxes)\n",
    "            boxes = boxes * scale_tensor\n",
    "            return bgr,boxes\n",
    "        return bgr,boxes\n",
    "\n",
    "    def randomCrop(self,bgr,boxes,labels):\n",
    "        if random.random() < 0.5:\n",
    "            center = (boxes[:,2:]+boxes[:,:2])/2\n",
    "            height,width,c = bgr.shape\n",
    "            h = random.uniform(0.6*height,height)\n",
    "            w = random.uniform(0.6*width,width)\n",
    "            x = random.uniform(0,width-w)\n",
    "            y = random.uniform(0,height-h)\n",
    "            x,y,h,w = int(x),int(y),int(h),int(w)\n",
    "\n",
    "            center = center - torch.FloatTensor([[x,y]]).expand_as(center)\n",
    "            mask1 = (center[:,0]>0) & (center[:,0]<w)\n",
    "            mask2 = (center[:,1]>0) & (center[:,1]<h)\n",
    "            mask = (mask1 & mask2).view(-1,1)\n",
    "\n",
    "            boxes_in = boxes[mask.expand_as(boxes)].view(-1,4)\n",
    "            if(len(boxes_in)==0):\n",
    "                return bgr,boxes,labels\n",
    "            box_shift = torch.FloatTensor([[x,y,x,y]]).expand_as(boxes_in)\n",
    "\n",
    "            boxes_in = boxes_in - box_shift\n",
    "            boxes_in[:,0]=boxes_in[:,0].clamp_(min=0,max=w)\n",
    "            boxes_in[:,2]=boxes_in[:,2].clamp_(min=0,max=w)\n",
    "            boxes_in[:,1]=boxes_in[:,1].clamp_(min=0,max=h)\n",
    "            boxes_in[:,3]=boxes_in[:,3].clamp_(min=0,max=h)\n",
    "\n",
    "            labels_in = labels[mask.view(-1)]\n",
    "            img_croped = bgr[y:y+h,x:x+w,:]\n",
    "            return img_croped,boxes_in,labels_in\n",
    "        return bgr,boxes,labels\n",
    "\n",
    "    def subMean(self,bgr,mean):\n",
    "        mean = np.array(mean, dtype=np.float32)\n",
    "        bgr = bgr - mean\n",
    "        return bgr\n",
    "\n",
    "    def random_flip(self, im, boxes):\n",
    "        if random.random() < 0.5:\n",
    "            im_lr = np.fliplr(im).copy()\n",
    "            h,w,_ = im.shape\n",
    "            xmin = w - boxes[:,2]\n",
    "            xmax = w - boxes[:,0]\n",
    "            boxes[:,0] = xmin\n",
    "            boxes[:,2] = xmax\n",
    "            return im_lr, boxes\n",
    "        return im, boxes\n",
    "    \n",
    "    def random_bright(self, im, delta=16):\n",
    "        alpha = random.random()\n",
    "        if alpha > 0.3:\n",
    "            im = im * alpha + random.randrange(-delta,delta)\n",
    "            im = im.clip(min=0,max=255).astype(np.uint8)\n",
    "        return im\n",
    "\n",
    "    \n",
    "def main():\n",
    "    from torch.utils.data import DataLoader\n",
    "    import torchvision.transforms as transforms\n",
    "    file_root = '/home/xzh/data/VOCdevkit/VOC2012/allimgs/'\n",
    "    train_dataset = yoloDataset(root=file_root,list_file='voc12_trainval.txt',train=True,transform = [transforms.ToTensor()] )\n",
    "    train_loader = DataLoader(train_dataset,batch_size=1,shuffle=False,num_workers=0)\n",
    "    train_iter = iter(train_loader)\n",
    "    for i in range(100):\n",
    "        img,target = next(train_iter)\n",
    "        print(img,target)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('object_tracking': conda)",
   "language": "python",
   "name": "python371064bitobjecttrackingconda66c6f2efc4d740808a4620e21504b8f3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
