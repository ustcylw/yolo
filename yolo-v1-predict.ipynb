{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "healthy-manufacturer",
   "metadata": {},
   "source": [
    "## predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hybrid-clear",
   "metadata": {
    "code_folding": [
     92
    ]
   },
   "outputs": [],
   "source": [
    "#encoding:utf-8\n",
    "#\n",
    "#created by xiongzihua\n",
    "#\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "\n",
    "from net import vgg16, vgg16_bn\n",
    "from resnet_yolo import resnet50\n",
    "import torchvision.transforms as transforms\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "VOC_CLASSES = (    # always index 0\n",
    "    'aeroplane', 'bicycle', 'bird', 'boat',\n",
    "    'bottle', 'bus', 'car', 'cat', 'chair',\n",
    "    'cow', 'diningtable', 'dog', 'horse',\n",
    "    'motorbike', 'person', 'pottedplant',\n",
    "'sheep', 'sofa', 'train', 'tvmonitor')\n",
    "\n",
    "Color = [[0, 0, 0],\n",
    "                    [128, 0, 0],\n",
    "                    [0, 128, 0],\n",
    "                    [128, 128, 0],\n",
    "                    [0, 0, 128],\n",
    "                    [128, 0, 128],\n",
    "                    [0, 128, 128],\n",
    "                    [128, 128, 128],\n",
    "                    [64, 0, 0],\n",
    "                    [192, 0, 0],\n",
    "                    [64, 128, 0],\n",
    "                    [192, 128, 0],\n",
    "                    [64, 0, 128],\n",
    "                    [192, 0, 128],\n",
    "                    [64, 128, 128],\n",
    "                    [192, 128, 128],\n",
    "                    [0, 64, 0],\n",
    "                    [128, 64, 0],\n",
    "                    [0, 192, 0],\n",
    "                    [128, 192, 0],\n",
    "                    [0, 64, 128]]\n",
    "\n",
    "def decoder(pred):\n",
    "    '''\n",
    "    pred (tensor) 1x7x7x30\n",
    "    return (tensor) box[[x1,y1,x2,y2]] label[...]\n",
    "    '''\n",
    "    grid_num = 14\n",
    "    boxes=[]\n",
    "    cls_indexs=[]\n",
    "    probs = []\n",
    "    cell_size = 1./grid_num\n",
    "    pred = pred.data\n",
    "    pred = pred.squeeze(0) #7x7x30\n",
    "    ## 获取P(obj)，即该gridcell是否包含目标。\n",
    "    contain1 = pred[:,:,4].unsqueeze(2)  # (S,S,1)\n",
    "    contain2 = pred[:,:,9].unsqueeze(2)  # (S,S,1)\n",
    "    contain = torch.cat((contain1,contain2),2)  # (S,S,2)\n",
    "    ## 计算P(obj)大于阈值的mask，即大于阈值，表示包含目标。\n",
    "    mask1 = contain > 0.1 #大于阈值 (S,S,2)\n",
    "    ## 计算P(obj)最大值的mask。\n",
    "    mask2 = (contain==contain.max()) # (S,S,2)  we always select the best contain_prob what ever it>0.9\n",
    "    ## P(obj)大于阈值的mask和P(obj)最大值mask的并集。\n",
    "    mask = (mask1+mask2).gt(0)  # (S,S,2)\n",
    "    # min_score,min_index = torch.min(contain,2) #每个cell只选最大概率的那个预测框\n",
    "    for i in range(grid_num):\n",
    "        for j in range(grid_num):\n",
    "            ## 计算第<i,j>位置的gridcell\n",
    "            for b in range(2):\n",
    "                ## 计算每个BBox\n",
    "                # index = min_index[i,j]\n",
    "                # mask[i,j,index] = 0\n",
    "                if mask[i,j,b] == 1:\n",
    "                    ## 如果第<i,j>位置的gridcell的第b个BBox预测包含目标。\n",
    "                    #print(i,j,b)\n",
    "                    box = pred[i,j,b*5:b*5+4]\n",
    "                    contain_prob = torch.FloatTensor([pred[i,j,b*5+4]])\n",
    "                    ## 获取第<i,j>位置的gridcell的左上角点坐标\n",
    "                    xy = torch.FloatTensor([j,i])*cell_size #cell左上角  up left of cell\n",
    "                    ## 计算目标左上角点的坐标\n",
    "                    ## box[:2]*cell_size：表示中心点相对第<i,j>位置左上角点的坐标\n",
    "                    ## box[:2]*cell_size + xy：表示中心点相对归一化图像坐标(值域[0,1])左上角点的坐标\n",
    "                    box[:2] = box[:2]*cell_size + xy # return cxcy relative to image\n",
    "                    ## 转化为(cx,cy,w,h)==>(x1,y1,x2,y2)形式的坐标\n",
    "                    box_xy = torch.FloatTensor(box.size())#转换成xy形式    convert[cx,cy,w,h] to [x1,xy1,x2,y2]\n",
    "                    box_xy[:2] = box[:2] - 0.5*box[2:]\n",
    "                    box_xy[2:] = box[:2] + 0.5*box[2:]\n",
    "                    ## 获取当前目标类别\n",
    "                    max_prob,cls_index = torch.max(pred[i,j,10:],0)\n",
    "                    if float((contain_prob*max_prob)[0]) > 0.1:\n",
    "                        ## 关键部分来了：\n",
    "                        ## P(cls|obj) = P(obj)*P(cls)\n",
    "                        ## 当前gridcell包含目标，并且预测的最大类别概率大于阈值\n",
    "                        boxes.append(box_xy.view(1,4))\n",
    "                        cls_indexs.append(cls_index)\n",
    "                        probs.append(contain_prob*max_prob)\n",
    "    if len(boxes) ==0:\n",
    "        boxes = torch.zeros((1,4))\n",
    "        probs = torch.zeros(1)\n",
    "        cls_indexs = torch.zeros(1)\n",
    "    else:\n",
    "        boxes = torch.cat(boxes,0) #(n,4)\n",
    "        probs = torch.cat(probs,0) #(n,)\n",
    "        cls_indexs = torch.cat(cls_indexs,0) #(n,)\n",
    "    keep = nms(boxes,probs)\n",
    "    return boxes[keep],cls_indexs[keep],probs[keep]\n",
    "\n",
    "def nms(bboxes,scores,threshold=0.5):\n",
    "    '''\n",
    "    NMS\n",
    "    包含IOU和score两个重要内容。\n",
    "    IOU：IOU作用就是选取最大的那个交并比的框。\n",
    "    score：score作用就是按照每个框的得分，进行挑选某个目标的框。\n",
    "    NMS过程：\n",
    "    1> 计算所有框的面积；\n",
    "    2> score排序；\n",
    "    3> 按照score排序，循环进行box挑选；\n",
    "      3.1> 保存当前score最高的order；\n",
    "      3.2> 取出当前最大score和最大score对应原来顺序的order；\n",
    "      3.3> 按照order[1:]取出剩余所有框；\n",
    "      3.4> 将当前框与剩余所有框进行对比，获取交集框的左上角点和右下角点；\n",
    "      3.5> 计算交集框的wh和面积；\n",
    "      3.6> 计算交并比；\n",
    "      3.7> 计算交并比小于T的下标；\n",
    "      3.8> 根据交并比小于T的下标，更新order(更新后的order全部是与当前box交并比小于T的box。)；\n",
    "    4> 返回所有score最高，且所有box之间IOU小于T的box的order;\n",
    "    bboxes(tensor) [N,4]\n",
    "    scores(tensor) [N,]\n",
    "    '''\n",
    "    ## 取出x1,y1,x2,y2坐标\n",
    "    x1 = bboxes[:,0]\n",
    "    y1 = bboxes[:,1]\n",
    "    x2 = bboxes[:,2]\n",
    "    y2 = bboxes[:,3]\n",
    "    ## 计算所有框的面积\n",
    "    areas = (x2-x1) * (y2-y1)\n",
    "\n",
    "    ## 排序所有框，主要获取排序后的order。\n",
    "    _,order = scores.sort(0,descending=True)\n",
    "    ## 保留的框\n",
    "    keep = []\n",
    "    ## 每次都检查剩余排序的order，直到所有排序后的order完成，即所有框都进行了nms。\n",
    "    while order.numel() > 0:\n",
    "        ## 保存当前得分最高的box的idx\n",
    "        i = order[0]\n",
    "        keep.append(i)\n",
    "\n",
    "        if order.numel() == 1:\n",
    "            break\n",
    "        \n",
    "        ## 计算当前最高score和剩余boxes交集左上角点和右下角点\n",
    "        xx1 = x1[order[1:]].clamp(min=x1[i])\n",
    "        yy1 = y1[order[1:]].clamp(min=y1[i])\n",
    "        xx2 = x2[order[1:]].clamp(max=x2[i])\n",
    "        yy2 = y2[order[1:]].clamp(max=y2[i])\n",
    "\n",
    "        ## 计算当前最高score的box剩余box交集的面积\n",
    "        w = (xx2-xx1).clamp(min=0)\n",
    "        h = (yy2-yy1).clamp(min=0)\n",
    "        inter = w*h\n",
    "\n",
    "        ## 计算当前最高score的box和剩余boxes的交并比\n",
    "        ovr = inter / (areas[i] + areas[order[1:]] - inter)\n",
    "        ## 挑选交并比低于阈值的idx\n",
    "        ids = (ovr<=threshold).nonzero().squeeze()\n",
    "        if ids.numel() == 0:\n",
    "            break\n",
    "        ## 在原来order中，用剩余boxes中交并比低于阈值的idx，挑选符合条件的order，并更新order。\n",
    "        order = order[ids+1]\n",
    "    return torch.LongTensor(keep)\n",
    "#\n",
    "#start predict one image\n",
    "#\n",
    "def predict_gpu(model,image_name,root_path=''):\n",
    "\n",
    "    result = []\n",
    "    image = cv2.imread(root_path+image_name)\n",
    "    h,w,_ = image.shape\n",
    "    img = cv2.resize(image,(448,448))\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "    mean = (123,117,104)#RGB\n",
    "    img = img - np.array(mean,dtype=np.float32)\n",
    "\n",
    "    transform = transforms.Compose([transforms.ToTensor(),])\n",
    "    img = transform(img)\n",
    "    img = Variable(img[None,:,:,:],volatile=True)\n",
    "    img = img.cuda()\n",
    "\n",
    "    pred = model(img) #1x7x7x30\n",
    "    pred = pred.cpu()\n",
    "    boxes,cls_indexs,probs =  decoder(pred)\n",
    "\n",
    "    for i,box in enumerate(boxes):\n",
    "        x1 = int(box[0]*w)\n",
    "        x2 = int(box[2]*w)\n",
    "        y1 = int(box[1]*h)\n",
    "        y2 = int(box[3]*h)\n",
    "        cls_index = cls_indexs[i]\n",
    "        cls_index = int(cls_index) # convert LongTensor to int\n",
    "        prob = probs[i]\n",
    "        prob = float(prob)\n",
    "        result.append([(x1,y1),(x2,y2),VOC_CLASSES[cls_index],image_name,prob])\n",
    "    return result\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    model = resnet50()\n",
    "    print('load model...')\n",
    "    model.load_state_dict(torch.load('best.pth'))\n",
    "    model.eval()\n",
    "    model.cuda()\n",
    "    image_name = 'dog.jpg'\n",
    "    image = cv2.imread(image_name)\n",
    "    print('predicting...')\n",
    "    result = predict_gpu(model,image_name)\n",
    "    for left_up,right_bottom,class_name,_,prob in result:\n",
    "        color = Color[VOC_CLASSES.index(class_name)]\n",
    "        cv2.rectangle(image,left_up,right_bottom,color,2)\n",
    "        label = class_name+str(round(prob,2))\n",
    "        text_size, baseline = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.4, 1)\n",
    "        p1 = (left_up[0], left_up[1]- text_size[1])\n",
    "        cv2.rectangle(image, (p1[0] - 2//2, p1[1] - 2 - baseline), (p1[0] + text_size[0], p1[1] + text_size[1]), color, -1)\n",
    "        cv2.putText(image, label, (p1[0], p1[1] + baseline), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255,255,255), 1, 8)\n",
    "\n",
    "    cv2.imwrite('result.jpg',image)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('object_tracking': conda)",
   "language": "python",
   "name": "python371064bitobjecttrackingconda66c6f2efc4d740808a4620e21504b8f3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
